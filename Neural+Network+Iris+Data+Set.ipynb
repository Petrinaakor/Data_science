{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network on Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Iris Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = np.atleast_2d(iris.target).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 4.8,  3. ,  1.4,  0.1],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 5.4,  3.9,  1.3,  0.4],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 5.7,  3.8,  1.7,  0.3],\n",
       "       [ 5.1,  3.8,  1.5,  0.3],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 4.6,  3.6,  1. ,  0.2],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 4.8,  3.4,  1.9,  0.2],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 5. ,  3.4,  1.6,  0.4],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.6,  0.2],\n",
       "       [ 4.8,  3.1,  1.6,  0.2],\n",
       "       [ 5.4,  3.4,  1.5,  0.4],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 5.5,  4.2,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 5.5,  3.5,  1.3,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 5. ,  3.5,  1.3,  0.3],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 5.1,  3.8,  1.9,  0.4],\n",
       "       [ 4.8,  3. ,  1.4,  0.3],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 4.6,  3.2,  1.4,  0.2],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 6.4,  3.2,  4.5,  1.5],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 6.5,  2.8,  4.6,  1.5],\n",
       "       [ 5.7,  2.8,  4.5,  1.3],\n",
       "       [ 6.3,  3.3,  4.7,  1.6],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 6. ,  2.2,  4. ,  1. ],\n",
       "       [ 6.1,  2.9,  4.7,  1.4],\n",
       "       [ 5.6,  2.9,  3.6,  1.3],\n",
       "       [ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 5.6,  3. ,  4.5,  1.5],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 6.2,  2.2,  4.5,  1.5],\n",
       "       [ 5.6,  2.5,  3.9,  1.1],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 6.1,  2.8,  4. ,  1.3],\n",
       "       [ 6.3,  2.5,  4.9,  1.5],\n",
       "       [ 6.1,  2.8,  4.7,  1.2],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 6.8,  2.8,  4.8,  1.4],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 6. ,  2.9,  4.5,  1.5],\n",
       "       [ 5.7,  2.6,  3.5,  1. ],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 6.7,  3.1,  4.7,  1.5],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 5.5,  2.6,  4.4,  1.2],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 5. ,  2.3,  3.3,  1. ],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 6.2,  2.9,  4.3,  1.3],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 6.3,  3.3,  6. ,  2.5],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 7.1,  3. ,  5.9,  2.1],\n",
       "       [ 6.3,  2.9,  5.6,  1.8],\n",
       "       [ 6.5,  3. ,  5.8,  2.2],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 4.9,  2.5,  4.5,  1.7],\n",
       "       [ 7.3,  2.9,  6.3,  1.8],\n",
       "       [ 6.7,  2.5,  5.8,  1.8],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 6.5,  3.2,  5.1,  2. ],\n",
       "       [ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 5.8,  2.8,  5.1,  2.4],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 6.5,  3. ,  5.5,  1.8],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 7.7,  2.6,  6.9,  2.3],\n",
       "       [ 6. ,  2.2,  5. ,  1.5],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 5.6,  2.8,  4.9,  2. ],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 7.2,  3.2,  6. ,  1.8],\n",
       "       [ 6.2,  2.8,  4.8,  1.8],\n",
       "       [ 6.1,  3. ,  4.9,  1.8],\n",
       "       [ 6.4,  2.8,  5.6,  2.1],\n",
       "       [ 7.2,  3. ,  5.8,  1.6],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 7.9,  3.8,  6.4,  2. ],\n",
       "       [ 6.4,  2.8,  5.6,  2.2],\n",
       "       [ 6.3,  2.8,  5.1,  1.5],\n",
       "       [ 6.1,  2.6,  5.6,  1.4],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 6.4,  3.1,  5.5,  1.8],\n",
       "       [ 6. ,  3. ,  4.8,  1.8],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 6.9,  3.1,  5.1,  2.3],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 6.8,  3.2,  5.9,  2.3],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 6.7,  3. ,  5.2,  2.3],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 6.2,  3.4,  5.4,  2.3],\n",
       "       [ 5.9,  3. ,  5.1,  1.8]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x, derivative=False):\n",
    "    if derivative:\n",
    "        return x * (1 - x)\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feedforward(X):\n",
    "    z_h = np.dot(X, w01)\n",
    "    a_h = sigmoid(z_h)\n",
    "\n",
    "    z_o = np.dot(a_h, w12)\n",
    "    a_o = sigmoid(z_o)\n",
    "    return(a_o,a_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Learning Rate\n",
    "eta = 0.01\n",
    "\n",
    "# Number of epochs for learning\n",
    "epochs = 1000\n",
    "\n",
    "# Number of Hidden Neurons\n",
    "hidden = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w01 = np.random.random((len(X[0]), hidden))\n",
    "w12 = np.random.random((hidden, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward and Back propogate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_total=[]\n",
    "error_total0=[]\n",
    "error_total1=[]\n",
    "error_total2=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    a_o, a_h = feedforward(X)\n",
    "    \n",
    "    # Calculate the error\n",
    "    a_o_error = ((1 / 2) * (np.power((a_o - y), 2)))\n",
    "\n",
    "    a_o_err_y = np.concatenate((a_o_error,y), axis=1)\n",
    "    a_o_err_y0 = a_o_err_y[a_o_err_y[:,1]==0][:,0]\n",
    "    a_o_err_y1 = a_o_err_y[a_o_err_y[:,1]==1][:,0]\n",
    "    a_o_err_y2 = a_o_err_y[a_o_err_y[:,1]==2][:,0]\n",
    "    \n",
    "    error_total = np.append(error_total,sum(a_o_error))\n",
    "    error_total0 = np.append(error_total0,sum(a_o_err_y0))\n",
    "    error_total1 = np.append(error_total1,sum(a_o_err_y1))\n",
    "    error_total2 = np.append(error_total2,sum(a_o_err_y2))\n",
    "\n",
    "    #print(sum(a_o_error))\n",
    "\n",
    "    # Backpropagation\n",
    "    ## Output to Hidden Layer weights\n",
    "    delta_a_o_error = a_o - y\n",
    "    delta_z_o = sigmoid(a_o,derivative=True)\n",
    "    delta_w12 = a_h\n",
    "    delta_output_layer = np.dot(delta_w12.T,(delta_a_o_error * delta_z_o))\n",
    "\n",
    "    ## Hidden to Input Layer weights\n",
    "    delta_a_h = np.dot(delta_a_o_error * delta_z_o, w12.T)\n",
    "    delta_z_h = sigmoid(a_h,derivative=True)\n",
    "    delta_w01 = X\n",
    "    delta_hidden_layer = np.dot(delta_w01.T, delta_a_h * delta_z_h)\n",
    "\n",
    "    # Adjust weights\n",
    "    w01 = w01 - eta * delta_hidden_layer\n",
    "    w12 = w12 - eta * delta_output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display final total error and type contribution to error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error: [ 25.21804767]\n",
      "Type 0 error: 0.0811213650694\n",
      "Type 1 error: 0.00293128297392\n",
      "Type 2 error: 25.1339950193\n"
     ]
    }
   ],
   "source": [
    "print(\"Total error:\",sum(a_o_error))\n",
    "print(\"Type 0 error:\",sum(a_o_err_y0))\n",
    "print(\"Type 1 error:\",sum(a_o_err_y1))\n",
    "print(\"Type 2 error:\",sum(a_o_err_y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Errors for each Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e3f5553cc0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4XHd97/H398yMVsuWZMmKN1l24pg4q4mz0NCwJJAU\naJzS53IppNeU0kALFHrvA4TLfe5De3kuoeV2JRTSAA1QoL2E3iwQqDEJIUASnIQkjh1HSbxvkjfJ\n1j4z3/vHObJGsmSNRrLnzOjzep55zn7m+9PyOWfOMsfcHRERKX1BsQsQEZGZoUAXESkTCnQRkTKh\nQBcRKRMKdBGRMqFAFxEpEwp0EZEyoUAXESkTCnQRkTKRPJtv1tTU5G1tbWfzLUVESt6TTz55yN2b\nJ5vvrAZ6W1sbmzZtOptvKSJS8sxsZz7z6ZCLiEiZUKCLiJQJBbqISJlQoIuIlAkFuohImcjrKhcz\n2wEcBzJA2t3Xmlkj8K9AG7ADeIe7Hz0zZYqIyGSmsof+Bne/zN3XRsO3ARvdfSWwMRoWEZEimc51\n6OuA10f9dwMPA5+YZj3j2rj1IM/sPhYOmIWdnOnRKCwaazkTbew8uRMLWT7nnceuyk5b26nvP3ba\ntNvG2BWe+r5j120GgRnJICARQCK3a0YiGHklg9HDicCoSATUVCSoqUhSlQrG/fmKyNmRb6A78GMz\nywBfdvc7gRZ33x9NPwC0jLegmd0K3ArQ2tpaUJE/fbGTbzy2Ez3+NN7MoCaVoLoiSW1lgvm1FbTM\nrWJBXSWL6qtZdU4dqxfNZUFdVbFLFSlLls9Dos1ssbvvNbMFwAbgw8B97l6fM89Rd2843XrWrl3r\nM32n6HD9w83w8aadHM6Zhp8ybrJ58lr3NJf30SvIu/6ReUZmyqdtWYdM1sm6k85E3ayTGfNKZ7Pj\nzjMwlKV3ME3vUIa+wQy90atnIM3hngEOdg/Q0d1Pd3/65Huft2AOb17dwu9d2crSxhpE5PTM7Mmc\nw90TymsP3d33Rt0OM/t34ErgoJktdPf9ZrYQ6JhWxQU6eShh3E/6+vgfF129Q2w90M1ze7p4aFsH\nX37kFb78yCusf00bH79xFVWpRLFLFCl5k+6hm1ktELj78ah/A/AXwHXAYXe/3cxuAxrd/eOnW9eZ\n2EOX0rTvWB9feOglvvX4Lq5oa+Cr77mCuqpUscsSiaV899DzucqlBXjUzJ4BngC+7+4/BG4H3mRm\n7cD10bBIXhbVV/O/f+di7njXq3lq1zE+cc+z5HP4T0QmNukhF3d/Bbh0nPGHCffSRQr21ksWsutI\nL5/74Qt8/7n9vO2SRcUuSaRk6U5RKbpbr13BqpY6/mbDi9pLF5kGBboUXSIwbr12BS939vDYK0eK\nXY5IyVKgSyy85eKF1FYkuP/ZfcUuRaRkKdAlFqorErx2ZRMPvdChwy4iBVKgS2y8ftUC9nf183Jn\nT7FLESlJCnSJjSvawhuNn9qlL+0UKYQCXWJjRdMc5lYleVqBLlIQBbrERhAYFy+Zx5Z93cUuRaQk\nKdAlVlYuqKO94wTZrE6MikyVAl1i5fyWOnoHM+w91lfsUkRKjgJdYuX8ljkAtHccL3IlIqVHgS6x\nsrKlDoAXD54ociUipUeBLrEyrzrFgrpK2hXoIlOmQJfYaWuqZdcR3VwkMlUKdImdZY017DjcW+wy\nREqOAl1ip62pls7jA/QOpiefWUROUqBL7LRGD47eqb10kSlRoEvstM2vBRToIlOlQJfYaZ0f7qHr\nxKjI1CjQJXbmVadoqEnpxKjIFCnQJZZa59eyS4EuMiUKdImltvk17DisQy4iU6FAl1ha1ljDvmN9\nDKazxS5FpGQo0CWWls2vJeuw56gOu4jkS4EusTRypYsCXSRfCnSJpWXRzUW7FegieVOgSyw111VS\nlQp0c5HIFCjQJZbMjNbGGh1yEZkCBbrElgJdZGoU6BJbrY217DrSi7seGC2Sj7wD3cwSZva0mT0Q\nDTea2QYza4+6DWeuTJmNWhur6R3McOjEYLFLESkJU9lD/wiwNWf4NmCju68ENkbDIjNGly6KTE1e\ngW5mS4C3AnfljF4H3B313w3cPLOlyWzX2hh+ja6+dVEkP/nuof8t8HEg9z7sFnffH/UfAFpmsjCR\nJQ3VmMGuw33FLkWkJEwa6Gb2NqDD3Z+caB4Pz1qNe+bKzG41s01mtqmzs7PwSmXWqUolOGduFTu1\nhy6Sl3z20K8BbjKzHcB3gDea2TeBg2a2ECDqdoy3sLvf6e5r3X1tc3PzDJUts8XSxhrdLSqSp0kD\n3d0/6e5L3L0NeCfwE3e/BbgPWB/Nth6494xVKbPWMl2LLpK36VyHfjvwJjNrB66PhkVmVGtjDQe7\nB+gfyhS7FJHYS05lZnd/GHg46j8MXDfzJYmMGL50cfeRXla21BW5GpF4052iEmut0bcu6ku6RCan\nQJdYGw50HUcXmZwCXWKtsbaCOZVJBbpIHhToEmtmxlJd6SKSFwW6xN6yxhp2HtbNRSKTUaBL7LXO\nr2H30T6yWX2NrsjpKNAl9pY21jCYznLweH+xSxGJNQW6xN7wA6N36dJFkdNSoEvs6dJFkfwo0CX2\nFjdUkwyM7Yd0YlTkdBToEnupRMDyplpePHii2KWIxJoCXUrC+efU8eLB48UuQyTWFOhSEla11LHr\nSC+9g+lilyISWwp0KQnnR9+0qMMuIhNToEtJWHVOFOgHdNhFZCIKdCkJrY01VCYDtuk4usiEFOhS\nEhKBcX5LHVv3dxe7FJHYUqBLybhkyTye29Ol73QRmYACXUrGpUvrOT6Q5pVDOjEqMh4FupSMNUvr\nAXh617EiVyISTwp0KRnnNs9hTmWSZ/Yo0EXGo0CXkhEExiVL5vHr3Qp0kfEo0KWkXL6sga37j9Pd\nP1TsUkRiR4EuJeWa85rIZJ3HXj5c7FJEYkeBLiVlTWs91akEj750qNiliMSOAl1KSmUywVUrGhXo\nIuNQoEvJee15TbzS2cOeo3qCkUguBbqUnOsvaAHgh5sPFLkSkXhRoEvJaWuq5aLFc7n/2f3FLkUk\nVhToUpLeevEintl9jN16cLTISQp0iS13x338L+J62yULAfjeU3vPZkkisTZpoJtZlZk9YWbPmNnz\nZvbn0fhGM9tgZu1Rt+HMlyuzRfrwYbbfdBPtv3ktPb/4xSnTlzbWcO35zXzriZ0MZbJFqFAkfvLZ\nQx8A3ujulwKXATea2dXAbcBGd18JbIyGRWbEkbu/zsBLLxNUVbHnw3/K4K5dp8yz/jXLONg9wH88\nf7AIFYrEz6SB7qHh7ytNRS8H1gF3R+PvBm4+IxXKrOPudN17L3OuvZZl3/g6AAc+85lTDr+8ftUC\nls2v4R9/+tKEh2ZEZpO8jqGbWcLMfg10ABvc/XGgxd2HLzM4ALRMsOytZrbJzDZ1dnbOSNFS3ob2\n7iV98CBz3vAGUgsX0vShD9HzyM848ZOfjJovERh/+saVbN7bzY+e1yWMInkFurtn3P0yYAlwpZld\nNGa6E+61j7fsne6+1t3XNjc3T7tgKX/9mzcDUHVx+GfWeMu7qVx5Hgc/ezvZ/v5R8968ZjHnNtfy\nlz/cxkA6c9ZrFYmTKV3l4u7HgIeAG4GDZrYQIOp2zHx5Mhv1b96MpVJUrVwJgKVStHzqUwzt2cOR\nr31t1LyJwPifv30hrxzq4YsPvVyMckViI5+rXJrNrD7qrwbeBLwA3Aesj2ZbD9x7poqU2aXvuc1U\nvupVWEXFyXG1V19N3Q03cOjLdzK0b9+o+V93fjM3XbqILz78Ek/vOnq2yxWJjXz20BcCD5nZs8Cv\nCI+hPwDcDrzJzNqB66NhkWlxd/q3bKHqwtWnTGv5+McAOPi5vzxl2l+su5CWuVV88F+e4kjP4Bmv\nUySO8rnK5Vl3X+Pul7j7Re7+F9H4w+5+nbuvdPfr3f3ImS9Xyt3Q3n1kjx+n6oJTAz21eDFNH3g/\nx3/0I7ruf2DUtPqaCr50y+Uc6hnkvf/8K04MpM9WySKxoTtFJVb6t24BoOqCV407ff773kf1mjUc\n+PSnT7k2/aLF8/iH31vDc3u7eO/XfkVXn55qJLOLAl1iZWDrCxAEVEYnRMeyZJJFf/VXkEiw+wN/\nTObY6OeL3nDhOfztf76Mp3Yd5e1f/Dk7DvWcjbJFYkGBLrHS/8ILVCxfTlBdPeE8FUsWs/SOLzC0\ne3cY6t3do6b/9qWL+Ob7ruJIzyC//Q+P8n837daNRzIrKNAlNtydvmefpWr1qcfPx6q54goW/Z/P\n0/f88+y85fcZOjD6xqKrV8znvg+9lgsWzeVj332W3//KE2ze23WmSheJBQW6xMbg9u1kDh2i5sor\n8pp/7pvfzNIv/SNDe/awfd3NdG/YMGr60sYavvNHV/PnN13I5n1dvO0fHuWD33qKp3Rpo5QpBbrE\nRs/Pw29VrL3yyryXmXPNNbTd811SS5aw98N/yp4Pf5jBnTtPTg8CY/1vtPHTj72BP3n9uTyyrZO3\nf/EXrPvCo3zjlzs4dGJgppshUjR2No8trl271jdt2nTW3k9Ky45330K2u5sV99835WV9cJDDX/0q\nh+78J3xwkLk33EDje9ZTffHFo+Y7MZDmnif38M3HdtLecYLA4Krl87n2/GZ+c2UTqxfOJQhsppok\nMiPM7El3XzvpfAp0iYP+F19k+03raP7oR2n6wPsLXk+6s5PDd32FY9/9LtmeHirOO5e5b3kLdddf\nT+XKlZiFYe3ubDt4nAee2c+GLQfZdvA4AA01Kda0NnDx4nlcunQeFy+up7muckbaKFIoBbqUDHdn\nzx//CT1PPMF5G39MsmH6z0rJnDhB9/330/39H9Ab/c0lmpqoveoqatZeTtXq1VSuWkVQVQVAR3c/\nP3/5ED9/6TDP7jlGe8cJhv81GmpSnNs8hxXNtVF3Dovrq1lUX8W86tTJjYTImaJAl5Lg7hz6wh0c\nuuMOFnziE8z/g/fM+HsMHTxIz6OP0vPLx+h5/DEynYfCCYkElSuWU7HiXCpaW6lY1kqqtZWKpUsZ\nqKtnS2cfz+3t4qWOE7zceYJXOntOOeZeU5Fg4bwqFtVXs3BeFY21lTTNqaCxtoL5cyqZX1vB/Gi4\nMpmY8bbJ7KBAl1hzd/o3P8+hO+7gxMMPM+/tb2fhZ/4XFpzZ8/TuTnrfPvq2bGFg61b6t2xlcMcO\nBvfuhaGcO0vNSDQ2klywgGRzU9htnM9QzRwOJ6o4YpV0UMm+bAV70wm2DyTY3ZvlSO8QQ5nx/6cq\nkwFzq1PUVSWpq0oxtyoZ9lemmFsdjqutTFKdSlBTkaAq6lZXJKhOjXSHp1UmA306mCUU6BIL2f5+\nMseOkTl6lKEDBxjcvoOB9nZ6Hn+M9L79BLW1NH3wgzS+Z/0ZD/PT8XQ6rG/nTob27CXd2Um6o+Pk\na6izg8yRo5A5zXeuB0F4Q1R1DV5VRbqyiqGKKgaTFfQnK+lPVNCbqKA3SNHnAb0e0OMBJ7Lhq8cD\nhhJJhoLoFfUP5gxnLCBtCTJBgAcBqYoKEqkkyYoklkyRSiWoSIZhXzH8SgSkEiPDldG44eFUND0Z\nGInAwm4iIDU8nDCSwcj0VCIYmS8wkomJp6USAUEACQuHLeoGBoEZQc6wNk4TyzfQk2ejmOnKHDtG\n5sTwLdwOHr3gZP/JDZPnzFPo9Nzndfjo93P3kXWcbvrJDWUh052Rx4VMMn241pz2jLxHFrJZPJOF\nbGZMN4tnM5A5tYuPWSaTwbNjlhkcxAcHyA4M4gMDeH8/2cGc/oEBMl1deF/fKb/PRGMjNZdfTu2t\n72fuW99Coq5u4l/+WWLJJBVLllCxZMmE87g72Z4esl1dZLq6yHR3kznWRaY7HM729uK9vWR7+8j2\n9pLtG+724ie6yPb0hsMDA/jg4Ok3DtOQCRJkgwTZICATJMhYQCbaCIQbhHCjkLaADEbGDCcga0bW\nDMfIWkDGjCELcDOy0TiP5sliuAUn+4enZaKuD683Z55w2eHhkXUBOAYWzmMW9g93iTYEI8NBzjxg\nFuSMjzYMFmCBhTsJ0caDaD4zw4KwNjPCeQ0IAqKZo/eLxg2/N+Fyw+vGDMudPxh5j/BCKQuvmIpq\nveGtV7Py3MVn5Hc+rCQCveNzn+HYv3+/2GXMLolE+M8wtjvcX5EiqKjEqqqwygqCikoS8+aF/ZVV\nWGU4nKivJ9FQT6KhgWRTE5XLl5Oory926wpiZiTmzCExZw6pxdP/x/R0OtowDoYbw9xXFPrhRjIa\nNzSIpzOQSYfLjun3TBom6Pd0GtIZPJPB00Mj/Zk0nsmG/dks2WgHwLMj4/zkTsFQOM59ZCOf8XDD\nH23wyWbDnYtRw1ks61E3HGfumGdn4LdSOo4s+Dwo0GHe4sNUX5lzd5+N6uT05A47p3yCm2B4ZD0+\nyfSJlvc81587zUfPNkmt4Q5CuJcQ7o0kwr2BIBHuKYwajoI3CMLxiQSWSITDiQQEiZPdcFoU0okk\nJJJYqgqSVZCsHNOtgmTFyLiKOVBVD9X1Od15kEghk7NkEksmoaaG2Xq61Ic3ADkvHzM83jjPRhuD\nseNyP4FH6/Zxx+V8ih31HuOMy+Z8Cj75XqPHnXzvcT7dD3/6z+crLaarJAK95h2foOaGdzNyaMFP\n/cGNN23cLgUuc5ppM1JTzqGcSZcJD4eMdDNjulMZn426Q+EhgMwQZAYhPRC9+ke6nuchgpomqG8N\nXw1tsPBSWHx5OKzjpJJjvPMm+gspXEkEOgteFb6kuDJpyERBP9QHgz3Qfwz6jo10+47C8X1wbBcc\n3AzbfhBuICAM99Xr4PL3QOOKYrZEpCyVRqBLPESHZKiozX+Z9CB0PA97NsG2B+GXd8AvvgBr3g1v\n/kx4iEZEZoQCXc6sZAUsWhO+rvwjOH4Afv538PiXYfsjcMv3YP65xa5SpCzo2xbl7Ko7B278LPzB\ngzBwHO6+CU50FrsqkbKgQJfiaL0q3Dvv6YD7PzL6hLWIFESBLsWz6DJ44/+Abd+HVx4udjUiJU+B\nLsV11Qdg7mJ49G+KXYlIyVOgS3ElK8PLGLf/FI7uKHY1IiVNgS7Fd8k7wu4L+noHkelQoEvxNbRB\n86vgxR8VuxKRkqZAl3g4942w+4nwqwdEpCAKdImHxZdDug86thS7EpGSpUCXeFgSfXf/Hj0ARaRQ\nCnSJh/plUDkXOrYWuxKRkjVpoJvZUjN7yMy2mNnzZvaRaHyjmW0ws/aoO/1HtcvsZQZNK+Fwe7Er\nESlZ+eyhp4H/5u6rgauBD5rZauA2YKO7rwQ2RsMihWs6Hw4p0EUKNWmgu/t+d38q6j8ObAUWA+uA\nu6PZ7gZuPlNFyiwx/zzo3gsDJ4pdiUhJmtIxdDNrA9YAjwMt7r4/mnQAaJnRymT2aWgLu127i1qG\nSKnKO9DNbA5wD/BRd+/Oneae++y1U5a71cw2mdmmzk59TaqcxrwlYbdrb3HrEClReQW6maUIw/xf\n3P170eiDZrYwmr4Q6BhvWXe/093Xuvva5ubmmahZytXc6Ino3XuKW4dIicrnKhcDvgJsdfe/zpl0\nH7A+6l8P3Dvz5cmsUrcQLNAeukiB8nkE3TXA7wPPmdmvo3H/Hbgd+Dcz+0NgJ/COM1OizBqJJMw5\nJzwxKiJTNmmgu/ujgE0w+bqZLUdmvbmLoHtfsasQKUm6U1TipbYZeg8VuwqRkqRAl3ipnQ89CnSR\nQijQJV5qm8NA10OjRaZMgS7xUtsM2SHo7yp2JSIlR4Eu8VLTFHZ12EVkyhToEi+1UaDrxKjIlCnQ\nJV5qo7uJe/Q1ESJTpUCXeKnVIReRQinQJV50DF2kYAp0iZdkBVTN0yEXkQIo0CV+app0UlSkAAp0\niZ/aJh1yESmAAl3ip2Y+9B4udhUiJUeBLvFTo+9zESmEAl3ip7Yp3EPX97mITIkCXeKnpknf5yJS\nAAW6xM/J2/91HF1kKhToEj+6uUikIAp0iZ/a+WFX16KLTIkCXeJHe+giBVGgS/zoGLpIQRToEj+p\nakjVKtBFpkiBLvGkm4tEpkyBLvFUO18nRUWmSIEu8VSjL+gSmSoFusRTXQucOFjsKkRKigJd4qlu\nERw/AJmhYlciUjIU6BJPcxcBrr10kSlQoEs8zV0cdrv3FbcOkRKiQJd4mrso7CrQRfKmQJd4UqCL\nTNmkgW5mXzWzDjPbnDOu0cw2mFl71G04s2XKrFPdAMkq6N5b7EpESkY+e+j/DNw4ZtxtwEZ3Xwls\njIZFZo5ZuJeuPXSRvE0a6O7+CHBkzOh1wN1R/93AzTNcl0h4YrRrT7GrECkZhR5Db3H3/VH/AaBl\nohnN7FYz22Rmmzo7Owt8O5mVGpbB0R3FrkKkZEz7pKi7OzDh03zd/U53X+vua5ubm6f7djKbNCyH\nng4YOFHsSkRKQqGBftDMFgJE3Y6ZK0kk0rg87GovXSQvhQb6fcD6qH89cO/MlCOSo2E40LcXtw6R\nEpHPZYvfBn4JrDKzPWb2h8DtwJvMrB24PhoWmVnDe+hHFOgi+UhONoO7/94Ek66b4VpERqtugKp6\n7aGL5El3ikq8zT8PDrUXuwqRkqBAl3hb8Cro2FrsKkRKggJd4m3B6vBRdCd0D4PIZBToEm8LLgi7\nndpLF5mMAl3ibcHqsKvDLiKTUqBLvM1pCa926dhS7EpEYk+BLvFmBs0XaA9dJA8KdIm/lgvhwGbI\nZopdiUisKdAl/pZcAUM92ksXmYQCXeJvydqwu+dXxa1DJOYU6BJ/jSvCE6N7NxW7EpFYU6BL/JnB\nkith5y+LXYlIrCnQpTSseB0ceRmO7S52JSKxpUCX0rDiDWH3lYeKW4dIjCnQpTQsuADmnAMv/bjY\nlYjElgJdSoMZrPotaP8xDPYWuxqRWFKgS+m48HfC69Hb/6PYlYjEkgJdSseya6B2ATz7r8WuRCSW\nFOhSOhJJWHMLvPhDOLar2NWIxI4CXUrL2veG3ce/XNw6RGJIgS6lpX4pXPJOeOKfoGtPsasRiRUF\nupSeN3wScPjJZ4pdiUisKNCl9NS3wms+BM98G7Y9WOxqRGJDgS6l6fW3QcvFcO8H4cgrxa5GJBYU\n6FKakpXwn/4Z3OGbv6vj6SIo0KWUNZ0H7/pX6DkEd10P+54udkUiRaVAl9K29Ep474/AEmGoP3w7\nDPUXuyqRolCgS+lrWQ0f+Fn41QAPfxb+/rLwOvX+7mJXJnJWKdClPNQ0wu/eBesfgIY2ePDj8Pnz\n4Xvvh633w8DxYlcocsYli12AyIxa/pvQ9iDsfQqe/jps/nd49jsQpGDRGlh8efiM0paLoHF5eHJV\npEyYuxe+sNmNwN8BCeAud7/9dPOvXbvWN23ScyHlLMoMwe7HoX1D2N33a0j3hdMsgPpl0LQy7Nad\nA3MXhd26hTCnBarmQZAobhtk1jOzJ9197WTzFbyHbmYJ4A7gTcAe4Fdmdp+7byl0nSIA7s6GnRu4\np/0e9p7YSypI0VrXyor6FaysX8nKhpW0zWsjFaQmX1kiBW2vDV8AmTR0bIHOF+BQOxxuh0Mvwe4n\noP/Y+OuonAfV88IHVVfVh93KOZCqhYqanG4NVNSGr1Q0nEiFnwISlTn9FTmvVPhd7yIzYDqHXK4E\nXnL3VwDM7DvAOkCBLgVJZ9NsO7qNO56+g5/t/RlL65Zy0fyL6M/0s717O4/seYS0pwFIBkmW1S1j\nQc0Cmmuaaa5upr6ynppUDbWpWmqSYbcqWUUySJ58pYIUqbkLSNYvInn+m0klUgQWEFiADfZhPR3Y\n8QMExw9iPZ1Yf1cY9H1Ho9cx6N4Hgz3ha6gHsunpNTwRhXwyCvkgFX4qCBIQJMOXBVF/NM5ypyfG\nnyd3nAVjXjamGwA2wXz5zDPZunKnkbMRi9aP5Yw/3bgxy4wax8TzxWHdcxeHOwJn0HQCfTGQ+8Te\nPcBV0ytnfF965ks8uH3kFm/n1MNE+Rw6GrvceMsUMs+47zVmuXFrLvS9fPJ5Yt+Ocd66N91LxjNU\nJ6v52NqP8a4L3kUyGPkTHcwMsr1rO+3H2mk/2s6Orh109nWy/cB2DvUdIj3dYJ1AYAGGYWYElQFW\nZQRWB9SFG4PoHzicK2pc9DM4OQzgPvyvHs2TMw3HRg2DuQODwODo9UA4rztkgMzw+qP1nHyL4RrG\nLJezrtGfDTxn+qlszC9tJj9XxHZdhR+RPsWnX/1nXH75+2duheM44ydFzexW4FaA1tbWgtbRXN3M\nefXnjV3vqe815lc5djgaOek8Y9c97jxj3yvPj835LFfIPOO+1xlqR8E/s0nmqU5W0zavjdcteR3z\nKuedsnxFooJVjatY1bjqlGlZz9KX7qNnqIeeoR560730DvXSl+4jnU2ffA1lh0aGPc1QZoiMZ3Ac\nd8dxsp49OZzbf3LaBPNlPTuqptNtMCfbUOYOn25nZbKN6enWc/r6ssM9o4ejjZXnbLRyN1i584yM\nG2d6bhWntM9Hz3JKnWOnj8wzel1j+n288bn1jzduovWNnTb59NoFF3KmFXxS1MxeA3za3W+Ihj8J\n4O6fnWgZnRQVEZm6fE+KTuc69F8BK81suZlVAO8E7pvG+kREZBoKPuTi7mkz+xDwI8LLFr/q7s/P\nWGUiIjIl0zqG7u4/AH4wQ7WIiMg06NZ/EZEyoUAXESkTCnQRkTKhQBcRKRMKdBGRMjGtb1uc8puZ\ndQI7C1y8CTg0g+WUArV5dlCbZ4fptHmZuzdPNtNZDfTpMLNN+dwpVU7U5tlBbZ4dzkabdchFRKRM\nKNBFRMpEKQX6ncUuoAjU5tlBbZ4dznibS+YYuoiInF4p7aGLiMhplESgm9mNZrbNzF4ys9uKXc9M\nMLOlZvaQmW0xs+fN7CPR+EYz22Bm7VG3IWeZT0Y/g21mdkPxqp8eM0uY2dNm9kA0XNZtNrN6M/uu\nmb1gZlvN7DWzoM1/Fv1dbzazb5tZVbm12cy+amYdZrY5Z9yU22hml5vZc9G0v7d8n5YzHneP9Yvw\nq3lfBlYAFcAzwOpi1zUD7VoIvDrqrwNeBFYDfwncFo2/Dfhc1L86anslsDz6mSSK3Y4C2/5fgW8B\nD0TDZd3Sg1CDAAACv0lEQVRm4G7gfVF/BVBfzm0mfDzldqA6Gv434D3l1mbgWuDVwOaccVNuI/AE\ncDXh89QeBH6r0JpKYQ/95MOo3X0QGH4YdUlz9/3u/lTUfxzYSviPsI4wAIi6N0f964DvuPuAu28H\nXiL82ZQUM1sCvBW4K2d02bbZzOYR/uN/BcDdB939GGXc5kgSqDazJFAD7KPM2uzujwBHxoyeUhvN\nbCEw190f8zDdv56zzJSVQqCP9zDqxUWq5YwwszZgDfA40OLu+6NJB4CWqL9cfg5/C3wcyH0AZzm3\neTnQCXwtOsx0l5nVUsZtdve9wOeBXcB+oMvd/4MybnOOqbZxcdQ/dnxBSiHQy5qZzQHuAT7q7t25\n06ItdtlchmRmbwM63P3JieYptzYT7qm+GvhHd18D9BB+FD+p3NocHTdeR7gxWwTUmtktufOUW5vH\nU4w2lkKg7wWW5gwvicaVPDNLEYb5v7j796LRB6OPYUTdjmh8OfwcrgFuMrMdhIfO3mhm36S827wH\n2OPuj0fD3yUM+HJu8/XAdnfvdPch4HvAb1DebR421TbujfrHji9IKQR6WT6MOjqT/RVgq7v/dc6k\n+4D1Uf964N6c8e80s0ozWw6sJDyZUjLc/ZPuvsTd2wh/jz9x91so7zYfAHab2apo1HXAFsq4zYSH\nWq42s5ro7/w6wnNE5dzmYVNqY3R4ptvMro5+Vv8lZ5mpK/aZ4jzPJr+F8CqQl4FPFbueGWrTawk/\njj0L/Dp6vQWYD2wE2oEfA405y3wq+hlsYxpnwuPwAl7PyFUuZd1m4DJgU/S7/n9Awyxo858DLwCb\ngW8QXt1RVm0Gvk14jmCI8JPYHxbSRmBt9HN6GfgC0Q2fhbx0p6iISJkohUMuIiKSBwW6iEiZUKCL\niJQJBbqISJlQoIuIlAkFuohImVCgi4iUCQW6iEiZ+P//0ux8wcyjRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e3f529ba90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(error_total)\n",
    "plt.plot(error_total0)\n",
    "plt.plot(error_total1)\n",
    "plt.plot(error_total2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Indepentant, dependent, predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1         3.5         1.4         0.2         0.          0.05288735]\n",
      " [ 4.9         3.          1.4         0.2         0.          0.05873043]\n",
      " [ 4.7         3.2         1.3         0.2         0.          0.05608767]\n",
      " [ 4.6         3.1         1.5         0.2         0.          0.06242867]\n",
      " [ 5.          3.6         1.4         0.2         0.          0.05265318]\n",
      " [ 5.4         3.9         1.7         0.4         0.          0.05324862]\n",
      " [ 4.6         3.4         1.4         0.3         0.          0.05714606]\n",
      " [ 5.          3.4         1.5         0.2         0.          0.05529186]\n",
      " [ 4.4         2.9         1.4         0.2         0.          0.06575659]\n",
      " [ 4.9         3.1         1.5         0.1         0.          0.0582784 ]\n",
      " [ 5.4         3.7         1.5         0.2         0.          0.05155884]\n",
      " [ 4.8         3.4         1.6         0.2         0.          0.05834438]\n",
      " [ 4.8         3.          1.4         0.1         0.          0.05837758]\n",
      " [ 4.3         3.          1.1         0.1         0.          0.05691156]\n",
      " [ 5.8         4.          1.2         0.2         0.          0.04868984]\n",
      " [ 5.7         4.4         1.5         0.4         0.          0.049122  ]\n",
      " [ 5.4         3.9         1.3         0.4         0.          0.05024642]\n",
      " [ 5.1         3.5         1.4         0.3         0.          0.05346892]\n",
      " [ 5.7         3.8         1.7         0.3         0.          0.05215148]\n",
      " [ 5.1         3.8         1.5         0.3         0.          0.05249456]\n",
      " [ 5.4         3.4         1.7         0.2         0.          0.05597043]\n",
      " [ 5.1         3.7         1.5         0.4         0.          0.05376621]\n",
      " [ 4.6         3.6         1.          0.2         0.          0.05124998]\n",
      " [ 5.1         3.3         1.7         0.5         0.          0.06427971]\n",
      " [ 4.8         3.4         1.9         0.2         0.          0.06707669]\n",
      " [ 5.          3.          1.6         0.2         0.          0.06273867]\n",
      " [ 5.          3.4         1.6         0.4         0.          0.05918443]\n",
      " [ 5.2         3.5         1.5         0.2         0.          0.05348138]\n",
      " [ 5.2         3.4         1.4         0.2         0.          0.05313513]\n",
      " [ 4.7         3.2         1.6         0.2         0.          0.06237095]\n",
      " [ 4.8         3.1         1.6         0.2         0.          0.06311619]\n",
      " [ 5.4         3.4         1.5         0.4         0.          0.05472713]\n",
      " [ 5.2         4.1         1.5         0.1         0.          0.0501222 ]\n",
      " [ 5.5         4.2         1.4         0.2         0.          0.04917564]\n",
      " [ 4.9         3.1         1.5         0.1         0.          0.0582784 ]\n",
      " [ 5.          3.2         1.2         0.2         0.          0.05335938]\n",
      " [ 5.5         3.5         1.3         0.2         0.          0.05087672]\n",
      " [ 4.9         3.1         1.5         0.1         0.          0.0582784 ]\n",
      " [ 4.4         3.          1.3         0.2         0.          0.06096831]\n",
      " [ 5.1         3.4         1.5         0.2         0.          0.05474645]\n",
      " [ 5.          3.5         1.3         0.3         0.          0.0528941 ]\n",
      " [ 4.5         2.3         1.3         0.3         0.          0.08061642]\n",
      " [ 4.4         3.2         1.3         0.2         0.          0.05815678]\n",
      " [ 5.          3.5         1.6         0.6         0.          0.06048953]\n",
      " [ 5.1         3.8         1.9         0.4         0.          0.05947665]\n",
      " [ 4.8         3.          1.4         0.3         0.          0.06094261]\n",
      " [ 5.1         3.8         1.6         0.2         0.          0.05289355]\n",
      " [ 4.6         3.2         1.4         0.2         0.          0.05850673]\n",
      " [ 5.3         3.7         1.5         0.2         0.          0.05187343]\n",
      " [ 5.          3.3         1.4         0.2         0.          0.05482866]\n",
      " [ 7.          3.2         4.7         1.4         1.          0.99349396]\n",
      " [ 6.4         3.2         4.5         1.5         1.          0.99414182]\n",
      " [ 6.9         3.1         4.9         1.5         1.          0.99581128]\n",
      " [ 5.5         2.3         4.          1.3         1.          0.99564085]\n",
      " [ 6.5         2.8         4.6         1.5         1.          0.99589314]\n",
      " [ 5.7         2.8         4.5         1.3         1.          0.99611259]\n",
      " [ 6.3         3.3         4.7         1.6         1.          0.99559622]\n",
      " [ 4.9         2.4         3.3         1.          1.          0.98427487]\n",
      " [ 6.6         2.9         4.6         1.3         1.          0.99484293]\n",
      " [ 5.2         2.7         3.9         1.4         1.          0.99464474]\n",
      " [ 5.          2.          3.5         1.          1.          0.99343383]\n",
      " [ 5.9         3.          4.2         1.5         1.          0.99410416]\n",
      " [ 6.          2.2         4.          1.          1.          0.99370352]\n",
      " [ 6.1         2.9         4.7         1.4         1.          0.99628116]\n",
      " [ 5.6         2.9         3.6         1.3         1.          0.98058503]\n",
      " [ 6.7         3.1         4.4         1.4         1.          0.99174366]\n",
      " [ 5.6         3.          4.5         1.5         1.          0.99620888]\n",
      " [ 5.8         2.7         4.1         1.          1.          0.99211534]\n",
      " [ 6.2         2.2         4.5         1.5         1.          0.99679457]\n",
      " [ 5.6         2.5         3.9         1.1         1.          0.99279278]\n",
      " [ 5.9         3.2         4.8         1.8         1.          0.99675673]\n",
      " [ 6.1         2.8         4.          1.3         1.          0.99054292]\n",
      " [ 6.3         2.5         4.9         1.5         1.          0.99702803]\n",
      " [ 6.1         2.8         4.7         1.2         1.          0.99611056]\n",
      " [ 6.4         2.9         4.3         1.3         1.          0.99271775]\n",
      " [ 6.6         3.          4.4         1.4         1.          0.99305763]\n",
      " [ 6.8         2.8         4.8         1.4         1.          0.99601979]\n",
      " [ 6.7         3.          5.          1.7         1.          0.99672528]\n",
      " [ 6.          2.9         4.5         1.5         1.          0.99594935]\n",
      " [ 5.7         2.6         3.5         1.          1.          0.97131782]\n",
      " [ 5.5         2.4         3.8         1.1         1.          0.99273579]\n",
      " [ 5.5         2.4         3.7         1.          1.          0.99008827]\n",
      " [ 5.8         2.7         3.9         1.2         1.          0.99069726]\n",
      " [ 6.          2.7         5.1         1.6         1.          0.99722719]\n",
      " [ 5.4         3.          4.5         1.5         1.          0.99639793]\n",
      " [ 6.          3.4         4.5         1.6         1.          0.99473573]\n",
      " [ 6.7         3.1         4.7         1.5         1.          0.99520873]\n",
      " [ 6.3         2.3         4.4         1.3         1.          0.99608385]\n",
      " [ 5.6         3.          4.1         1.3         1.          0.99297522]\n",
      " [ 5.5         2.5         4.          1.3         1.          0.9950199 ]\n",
      " [ 5.5         2.6         4.4         1.2         1.          0.99621082]\n",
      " [ 6.1         3.          4.6         1.4         1.          0.99574369]\n",
      " [ 5.8         2.6         4.          1.2         1.          0.99312605]\n",
      " [ 5.          2.3         3.3         1.          1.          0.98529553]\n",
      " [ 5.6         2.7         4.2         1.3         1.          0.99527007]\n",
      " [ 5.7         3.          4.2         1.2         1.          0.99305559]\n",
      " [ 5.7         2.9         4.2         1.3         1.          0.9942301 ]\n",
      " [ 6.2         2.9         4.3         1.3         1.          0.99352924]\n",
      " [ 5.1         2.5         3.          1.1         1.          0.94805683]\n",
      " [ 5.7         2.8         4.1         1.3         1.          0.99388158]\n",
      " [ 6.3         3.3         6.          2.5         2.          0.99749884]\n",
      " [ 5.8         2.7         5.1         1.9         2.          0.99735049]\n",
      " [ 7.1         3.          5.9         2.1         2.          0.9974321 ]\n",
      " [ 6.3         2.9         5.6         1.8         2.          0.99739792]\n",
      " [ 6.5         3.          5.8         2.2         2.          0.99746508]\n",
      " [ 7.6         3.          6.6         2.1         2.          0.99750631]\n",
      " [ 4.9         2.5         4.5         1.7         2.          0.99720889]\n",
      " [ 7.3         2.9         6.3         1.8         2.          0.99747073]\n",
      " [ 6.7         2.5         5.8         1.8         2.          0.99746449]\n",
      " [ 7.2         3.6         6.1         2.5         2.          0.99743972]\n",
      " [ 6.5         3.2         5.1         2.          2.          0.99702667]\n",
      " [ 6.4         2.7         5.3         1.9         2.          0.99734543]\n",
      " [ 6.8         3.          5.5         2.1         2.          0.99734295]\n",
      " [ 5.7         2.5         5.          2.          2.          0.99739048]\n",
      " [ 5.8         2.8         5.1         2.4         2.          0.99742135]\n",
      " [ 6.4         3.2         5.3         2.3         2.          0.99731528]\n",
      " [ 6.5         3.          5.5         1.8         2.          0.99731289]\n",
      " [ 7.7         3.8         6.7         2.2         2.          0.99746313]\n",
      " [ 7.7         2.6         6.9         2.3         2.          0.99753736]\n",
      " [ 6.          2.2         5.          1.5         2.          0.99730644]\n",
      " [ 6.9         3.2         5.7         2.3         2.          0.99739775]\n",
      " [ 5.6         2.8         4.9         2.          2.          0.99729224]\n",
      " [ 7.7         2.8         6.7         2.          2.          0.99751567]\n",
      " [ 6.3         2.7         4.9         1.8         2.          0.99708231]\n",
      " [ 6.7         3.3         5.7         2.1         2.          0.99736333]\n",
      " [ 7.2         3.2         6.          1.8         2.          0.99736523]\n",
      " [ 6.2         2.8         4.8         1.8         2.          0.9969488 ]\n",
      " [ 6.1         3.          4.9         1.8         2.          0.99696621]\n",
      " [ 6.4         2.8         5.6         2.1         2.          0.99744688]\n",
      " [ 7.2         3.          5.8         1.6         2.          0.99727972]\n",
      " [ 7.4         2.8         6.1         1.9         2.          0.99745172]\n",
      " [ 7.9         3.8         6.4         2.          2.          0.99733012]\n",
      " [ 6.4         2.8         5.6         2.2         2.          0.99745782]\n",
      " [ 6.3         2.8         5.1         1.5         2.          0.99704625]\n",
      " [ 6.1         2.6         5.6         1.4         2.          0.99740145]\n",
      " [ 7.7         3.          6.1         2.3         2.          0.99745352]\n",
      " [ 6.3         3.4         5.6         2.4         2.          0.99741126]\n",
      " [ 6.4         3.1         5.5         1.8         2.          0.99730104]\n",
      " [ 6.          3.          4.8         1.8         2.          0.99688424]\n",
      " [ 6.9         3.1         5.4         2.1         2.          0.99724746]\n",
      " [ 6.7         3.1         5.6         2.4         2.          0.99742152]\n",
      " [ 6.9         3.1         5.1         2.3         2.          0.99711323]\n",
      " [ 5.8         2.7         5.1         1.9         2.          0.99735049]\n",
      " [ 6.8         3.2         5.9         2.3         2.          0.997453  ]\n",
      " [ 6.7         3.3         5.7         2.5         2.          0.99743022]\n",
      " [ 6.7         3.          5.2         2.3         2.          0.99727283]\n",
      " [ 6.3         2.5         5.          1.9         2.          0.99727991]\n",
      " [ 6.5         3.          5.2         2.          2.          0.99721197]\n",
      " [ 6.2         3.4         5.4         2.3         2.          0.99733699]\n",
      " [ 5.9         3.          5.1         1.8         2.          0.99720876]]\n"
     ]
    }
   ],
   "source": [
    "a_o, a_h = feedforward(X)\n",
    "print(np.concatenate((X,y,a_o),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
